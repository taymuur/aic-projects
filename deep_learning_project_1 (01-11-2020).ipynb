{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SONAR - Binary Classification Project for Navy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing classes and functions\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "dataframe = pandas.read_csv(\"sonar.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "# splitting into input (X) and output (Y) variables\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting string values to integer using labelencoder\n",
    "le = LabelEncoder()\n",
    "le.fit(Y)\n",
    "encoded_Y=le.transform(Y)\n",
    "encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def create_baseline():\n",
    "    \n",
    "    # creating model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(60, activation='relu', input_shape=(60,)))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compiling model\n",
    "    model.compile(optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_baseline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "208/208 [==============================] - 2s 10ms/step - loss: 0.6801 - accuracy: 0.5625\n",
      "Epoch 2/20\n",
      "208/208 [==============================] - 0s 341us/step - loss: 0.6205 - accuracy: 0.6923\n",
      "Epoch 3/20\n",
      "208/208 [==============================] - 0s 360us/step - loss: 0.5923 - accuracy: 0.7356\n",
      "Epoch 4/20\n",
      "208/208 [==============================] - 0s 346us/step - loss: 0.5602 - accuracy: 0.7885\n",
      "Epoch 5/20\n",
      "208/208 [==============================] - 0s 365us/step - loss: 0.5452 - accuracy: 0.7212\n",
      "Epoch 6/20\n",
      "208/208 [==============================] - 0s 356us/step - loss: 0.5232 - accuracy: 0.7644\n",
      "Epoch 7/20\n",
      "208/208 [==============================] - 0s 356us/step - loss: 0.5045 - accuracy: 0.7837\n",
      "Epoch 8/20\n",
      "208/208 [==============================] - 0s 365us/step - loss: 0.4916 - accuracy: 0.7740\n",
      "Epoch 9/20\n",
      "208/208 [==============================] - 0s 351us/step - loss: 0.4775 - accuracy: 0.7933\n",
      "Epoch 10/20\n",
      "208/208 [==============================] - 0s 360us/step - loss: 0.4602 - accuracy: 0.7981\n",
      "Epoch 11/20\n",
      "208/208 [==============================] - 0s 365us/step - loss: 0.4697 - accuracy: 0.7788\n",
      "Epoch 12/20\n",
      "208/208 [==============================] - 0s 365us/step - loss: 0.4469 - accuracy: 0.8077\n",
      "Epoch 13/20\n",
      "208/208 [==============================] - 0s 336us/step - loss: 0.4401 - accuracy: 0.8029\n",
      "Epoch 14/20\n",
      "208/208 [==============================] - 0s 375us/step - loss: 0.4283 - accuracy: 0.8077\n",
      "Epoch 15/20\n",
      "208/208 [==============================] - 0s 332us/step - loss: 0.4232 - accuracy: 0.8221\n",
      "Epoch 16/20\n",
      "208/208 [==============================] - 0s 380us/step - loss: 0.4167 - accuracy: 0.7933\n",
      "Epoch 17/20\n",
      "208/208 [==============================] - 0s 346us/step - loss: 0.4151 - accuracy: 0.8173\n",
      "Epoch 18/20\n",
      "208/208 [==============================] - 0s 375us/step - loss: 0.4144 - accuracy: 0.8173\n",
      "Epoch 19/20\n",
      "208/208 [==============================] - 0s 346us/step - loss: 0.4043 - accuracy: 0.8173\n",
      "Epoch 20/20\n",
      "208/208 [==============================] - 0s 375us/step - loss: 0.3962 - accuracy: 0.8269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1baae87bfd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,\n",
    "          encoded_Y,\n",
    "          epochs=20,\n",
    "          batch_size=5\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 82.21% (5.73%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 84.59% (6.01%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline model with standardized dataset\n",
    "\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller model\n",
    "def create_smaller():\n",
    "    \n",
    "    # create model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(30, activation='relu', input_shape=(60,)))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 83.59% (5.54%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger model\n",
    "def create_larger():\n",
    "\n",
    "    # create model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(60, activation='relu', input_shape=(60,)))\n",
    "    model.add(layers.Dense(30, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 83.16% (4.42%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = X[:60]\n",
    "partial_x_train = X[60:]\n",
    "\n",
    "y_val = encoded_Y[:60]\n",
    "partial_y_train = encoded_Y[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148 samples, validate on 60 samples\n",
      "Epoch 1/30\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.7500 - val_loss: 1.4003 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "148/148 [==============================] - 0s 412us/step - loss: 0.5341 - accuracy: 0.7500 - val_loss: 1.2754 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "148/148 [==============================] - 0s 412us/step - loss: 0.5096 - accuracy: 0.7500 - val_loss: 1.3694 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "148/148 [==============================] - 0s 547us/step - loss: 0.4693 - accuracy: 0.7500 - val_loss: 1.1894 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "148/148 [==============================] - 0s 533us/step - loss: 0.4038 - accuracy: 0.7500 - val_loss: 1.3187 - val_accuracy: 0.2667\n",
      "Epoch 6/30\n",
      "148/148 [==============================] - 0s 506us/step - loss: 0.3193 - accuracy: 0.8514 - val_loss: 1.3055 - val_accuracy: 0.3500\n",
      "Epoch 7/30\n",
      "148/148 [==============================] - 0s 540us/step - loss: 0.2586 - accuracy: 0.9122 - val_loss: 1.7484 - val_accuracy: 0.3667\n",
      "Epoch 8/30\n",
      "148/148 [==============================] - 0s 520us/step - loss: 0.2423 - accuracy: 0.9324 - val_loss: 1.3827 - val_accuracy: 0.4333\n",
      "Epoch 9/30\n",
      "148/148 [==============================] - 0s 479us/step - loss: 0.1734 - accuracy: 0.9324 - val_loss: 1.8013 - val_accuracy: 0.4000\n",
      "Epoch 10/30\n",
      "148/148 [==============================] - 0s 479us/step - loss: 0.1423 - accuracy: 0.9527 - val_loss: 2.2484 - val_accuracy: 0.4000\n",
      "Epoch 11/30\n",
      "148/148 [==============================] - 0s 419us/step - loss: 0.1438 - accuracy: 0.9392 - val_loss: 1.4524 - val_accuracy: 0.5167\n",
      "Epoch 12/30\n",
      "148/148 [==============================] - 0s 419us/step - loss: 0.1459 - accuracy: 0.9527 - val_loss: 2.8334 - val_accuracy: 0.3833\n",
      "Epoch 13/30\n",
      "148/148 [==============================] - 0s 520us/step - loss: 0.2228 - accuracy: 0.9324 - val_loss: 2.2617 - val_accuracy: 0.4000\n",
      "Epoch 14/30\n",
      "148/148 [==============================] - 0s 493us/step - loss: 0.0898 - accuracy: 0.9797 - val_loss: 2.6391 - val_accuracy: 0.4000\n",
      "Epoch 15/30\n",
      "148/148 [==============================] - 0s 419us/step - loss: 0.0918 - accuracy: 0.9730 - val_loss: 2.6050 - val_accuracy: 0.4000\n",
      "Epoch 16/30\n",
      "148/148 [==============================] - 0s 500us/step - loss: 0.0718 - accuracy: 0.9797 - val_loss: 2.2745 - val_accuracy: 0.4667\n",
      "Epoch 17/30\n",
      "148/148 [==============================] - 0s 419us/step - loss: 0.0590 - accuracy: 0.9865 - val_loss: 2.0381 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "148/148 [==============================] - 0s 479us/step - loss: 0.0688 - accuracy: 0.9797 - val_loss: 3.0813 - val_accuracy: 0.4000\n",
      "Epoch 19/30\n",
      "148/148 [==============================] - 0s 540us/step - loss: 0.0544 - accuracy: 0.9865 - val_loss: 2.8517 - val_accuracy: 0.4000\n",
      "Epoch 20/30\n",
      "148/148 [==============================] - 0s 473us/step - loss: 0.0782 - accuracy: 0.9730 - val_loss: 3.0360 - val_accuracy: 0.4000\n",
      "Epoch 21/30\n",
      "148/148 [==============================] - 0s 520us/step - loss: 0.0535 - accuracy: 0.9797 - val_loss: 2.2590 - val_accuracy: 0.4833\n",
      "Epoch 22/30\n",
      "148/148 [==============================] - 0s 520us/step - loss: 0.0516 - accuracy: 0.9797 - val_loss: 2.4424 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "148/148 [==============================] - 0s 513us/step - loss: 0.0428 - accuracy: 0.9730 - val_loss: 2.9862 - val_accuracy: 0.4167\n",
      "Epoch 24/30\n",
      "148/148 [==============================] - 0s 527us/step - loss: 0.0325 - accuracy: 0.9932 - val_loss: 3.3647 - val_accuracy: 0.4000\n",
      "Epoch 25/30\n",
      "148/148 [==============================] - 0s 527us/step - loss: 0.0405 - accuracy: 0.9932 - val_loss: 3.3298 - val_accuracy: 0.4000\n",
      "Epoch 26/30\n",
      "148/148 [==============================] - 0s 527us/step - loss: 0.0250 - accuracy: 0.9932 - val_loss: 3.3132 - val_accuracy: 0.4000\n",
      "Epoch 27/30\n",
      "148/148 [==============================] - 0s 554us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 3.7960 - val_accuracy: 0.4000\n",
      "Epoch 28/30\n",
      "148/148 [==============================] - 0s 533us/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 4.0177 - val_accuracy: 0.4000\n",
      "Epoch 29/30\n",
      "148/148 [==============================] - 0s 520us/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 3.7684 - val_accuracy: 0.4000\n",
      "Epoch 30/30\n",
      "148/148 [==============================] - 0s 540us/step - loss: 0.0305 - accuracy: 0.9865 - val_loss: 3.8716 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1bab9363630>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# creating model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(60, activation='relu', input_shape=(60,)))\n",
    "model.add(layers.Dense(60, activation='relu'))\n",
    "model.add(layers.Dense(30, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compiling model\n",
    "model.compile(optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "        partial_y_train,\n",
    "        epochs=30,\n",
    "        batch_size=5,\n",
    "        validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras' has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-01fe5e28af8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras' has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "# using the functional API\n",
    "import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(60,))\n",
    "X = layers.Dense(60, activation='relu')(X)\n",
    "X = layers.Dense(30, activation='relu')(X)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(X)\n",
    "\n",
    "model = keras.model(inputs, outputs)\n",
    "\n",
    "model.fit(X, encoded_Y, epochs = 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
